plugins:
  flink:
    flinkPropertiesOverride:
      - jobmanager.archive.fs.dir: "flink-job-archive-dir"
    defaultFlinkCluster:
      spec:
        serviceAccountName: "flink-service-account"
        flinkVersion: "v1.12"
        image:
          name: "flink-image"
          pullPolicy: Always
        job:
          jarFile: /jars/job.jar
          cleanupPolicy:
            afterJobSucceeds: "DeleteCluster"
            afterJobFails: "DeleteCluster"
            afterJobCancelled: "DeleteCluster"
          volumes:
            - name: jars
          volumeMounts:
            - mountPath: /jars
              name: jars
          initContainers:
            - name: gcs-downloader
              image: google/cloud-sdk
              command: ["/bin/sh"]
              args:
                - "-c"
                - >-
                  apt install -y zip &&
                  mkdir lib &&
                  if [ -n "${GOOGLE_APPLICATION_CREDENTIALS}" ]; then gcloud auth activate-service-account --key-file $GOOGLE_APPLICATION_CREDENTIALS; fi &&
                  gsutil -m cp {{join .Artifacts " "}} lib &&
                  zip -r job.jar .
              resources:
                limits:
                  cpu: "2"
                  memory: "1Gi"
        jobManager:
          accessScope: External
          ingress:
            useTls: true
          resources:
            limits:
              cpu: "3.5"
          volumes:
            - name: cache-volume
              emptyDir: {}
          volumeMounts:
            - mountPath: /cache
              name: cache-volume
            - name: pvc-jm-default
              mountPath: /flink-tmp
          volumeClaimTemplates:
            - metadata:
                name: pvc-jm-default
              spec:
                accessModes: ["ReadWriteOnce"]
                storageClassName: "pd-standard"
                resources:
                  requests:
                    storage: 250Gi
          nodeSelector:
            - gke-nodepool: "nodepool-1"
          sidecars:
            - name: "sidecar"
              image: "sidecar-image"
              command: ["printenv"]
              args: ["HOSTNAME", "KUBERNETES_PORT"]
        taskManager:
          replicas: 4
          volumes:
            - name: cache-volume
              emptyDir: {}
          volumeMounts:
            - mountPath: /cache
              name: cache-volume
            - name: pvc-tm-default
              mountPath: /flink-tmp
          volumeClaimTemplates:
            - metadata:
                name: pvc-tm-default
              spec:
                accessModes: ["ReadWriteOnce"]
                storageClassName: "pd-standard"
                resources:
                  requests:
                    storage: 250Gi
          nodeSelector:
            - gke-nodepool: "nodepool-2"
        flinkProperties:
          - akka.ask.timeout: "600s"
          - blob.server.port: "6124"
          - resourcemanager.taskmanager-timeout: "3600000"
          - web.timeout: "600000"
          - heartbeat.timeout: "3600000"
          - pipeline.object-reuse: "true"
        logConfig:
          - log4j.rootLogger: "INFO, console, file"
          - log4j.logger.org.apache.flink: "INFO"
          - log4j.logger.akka: "INFO"
          - log4j.logger.org.apache.kafka: "INFO"
          - log4j.logger.org.apache.hadoop: "INFO"
          - log4j.logger.org.apache.zookeeper: "INFO"
          # Log all infos to the console
          - log4j.appender.console: "org.apache.log4j.ConsoleAppender"
          - log4j.appender.console.layout: "org.apache.log4j.PatternLayout"
          - log4j.appender.console.layout.ConversionPattern: "%d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %-60c %x - %m%n"
